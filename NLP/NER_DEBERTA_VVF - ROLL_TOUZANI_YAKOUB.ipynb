{"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"818b493249004176990be11738f8ed3a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_6b06f4434e774eddbf740a8f7852d8f7","IPY_MODEL_50917851b1334ec8b81a7923441d6ebe","IPY_MODEL_00dc1751b4724f039a338bcd4ba78904"],"layout":"IPY_MODEL_8595fe1edae6464da0e10b5308bc1ea6"}},"6b06f4434e774eddbf740a8f7852d8f7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d2e6e895e06147d082245b9f417c5171","placeholder":"​","style":"IPY_MODEL_a0d435541b2e4b679c9f5a4a5e195d4a","value":"Map: 100%"}},"50917851b1334ec8b81a7923441d6ebe":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d98dadaff55e4908a2458aafa87a19d1","max":3250,"min":0,"orientation":"horizontal","style":"IPY_MODEL_b32553f291bb43709487df61408194f2","value":3250}},"00dc1751b4724f039a338bcd4ba78904":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_6b27720481bb494797ac15fe9088bd49","placeholder":"​","style":"IPY_MODEL_f2832180fa614a50bd5fc3d8452f0845","value":" 3250/3250 [00:00&lt;00:00, 7082.48 examples/s]"}},"8595fe1edae6464da0e10b5308bc1ea6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d2e6e895e06147d082245b9f417c5171":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a0d435541b2e4b679c9f5a4a5e195d4a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d98dadaff55e4908a2458aafa87a19d1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b32553f291bb43709487df61408194f2":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"6b27720481bb494797ac15fe9088bd49":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f2832180fa614a50bd5fc3d8452f0845":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"c420e709f498434d858abd5a27b5efb8":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_24bfdf5a2e2c407b97e73f4aa874c164","IPY_MODEL_8495f4fcaef5475eb9cee77d455a8905","IPY_MODEL_47a8bffe7c2b49afb26a4b31a30a3fa8"],"layout":"IPY_MODEL_76af4811767f4b2a9c00b66b16604578"}},"24bfdf5a2e2c407b97e73f4aa874c164":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_250ed216ebd24866a5c82be18e12d581","placeholder":"​","style":"IPY_MODEL_da07eca3e88143aeac5ea901486de47f","value":"100%"}},"8495f4fcaef5475eb9cee77d455a8905":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"","description":"","description_tooltip":null,"layout":"IPY_MODEL_9c5bf67865964c74814fc3ecb3184eaf","max":5268,"min":0,"orientation":"horizontal","style":"IPY_MODEL_71c4f051167d493a867d7210ab9f9b9b","value":5268}},"47a8bffe7c2b49afb26a4b31a30a3fa8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_1f0b363f1ed54e83a0e9eb026b23ffac","placeholder":"​","style":"IPY_MODEL_caa5f951c2a54af2bc7957b95ab2d3a5","value":" 5268/5268 [08:38&lt;00:00, 11.13it/s]"}},"76af4811767f4b2a9c00b66b16604578":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"250ed216ebd24866a5c82be18e12d581":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"da07eca3e88143aeac5ea901486de47f":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"9c5bf67865964c74814fc3ecb3184eaf":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"71c4f051167d493a867d7210ab9f9b9b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"1f0b363f1ed54e83a0e9eb026b23ffac":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"caa5f951c2a54af2bc7957b95ab2d3a5":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Installation et importation des librairies:","metadata":{"id":"z4pwiOUQOpyj"}},{"cell_type":"code","source":"pip install datasets transformers evaluate seqeval accelerate","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wPj2XMolFnxe","outputId":"bb27af73-9d92-4168-fcb0-92b61d8daa56","execution":{"iopub.status.busy":"2024-04-01T17:52:03.764933Z","iopub.execute_input":"2024-04-01T17:52:03.765327Z","iopub.status.idle":"2024-04-01T17:52:16.522548Z","shell.execute_reply.started":"2024-04-01T17:52:03.765295Z","shell.execute_reply":"2024-04-01T17:52:16.521421Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.1.0)\nRequirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.38.2)\nRequirement already satisfied: evaluate in /opt/conda/lib/python3.10/site-packages (0.4.1)\nRequirement already satisfied: seqeval in /opt/conda/lib/python3.10/site-packages (1.2.2)\nRequirement already satisfied: accelerate in /opt/conda/lib/python3.10/site-packages (0.28.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=5.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (11.0.0)\nRequirement already satisfied: dill in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.1.4)\nRequirement already satisfied: requests>=2.19.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.31.0)\nRequirement already satisfied: tqdm>=4.62.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.1)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec>=2021.05.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]>=2021.05.0->datasets) (2024.3.0)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.1)\nRequirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.21.4)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: responses<0.19 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.18.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\nRequirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.2)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.2)\nRequirement already satisfied: scikit-learn>=0.21.3 in /opt/conda/lib/python3.10/site-packages (from seqeval) (1.2.2)\nRequirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from accelerate) (5.9.3)\nRequirement already satisfied: torch>=1.10.0 in /opt/conda/lib/python3.10/site-packages (from accelerate) (2.1.2)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.4)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.3)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.9.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\nRequirement already satisfied: scipy>=1.3.2 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2023.4)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorForTokenClassification, AutoModelForTokenClassification, get_scheduler, pipeline\nimport torch\nfrom torch.utils.data import DataLoader\nfrom torch.optim import Adam\nimport evaluate\nfrom tqdm.auto import tqdm\nfrom accelerate import Accelerator","metadata":{"id":"eemg4rtga6iS","execution":{"iopub.status.busy":"2024-04-01T17:52:16.525008Z","iopub.execute_input":"2024-04-01T17:52:16.525513Z","iopub.status.idle":"2024-04-01T17:52:24.994302Z","shell.execute_reply.started":"2024-04-01T17:52:16.525475Z","shell.execute_reply":"2024-04-01T17:52:24.993501Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-04-01 17:52:21.360619: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-04-01 17:52:21.360671: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-04-01 17:52:21.362266: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Data:","metadata":{"id":"OPnt8gePOxFY"}},{"cell_type":"code","source":"raw_datasets = load_dataset(\"conll2003\")","metadata":{"id":"Of43rItyEsgK","execution":{"iopub.status.busy":"2024-04-01T17:52:24.995320Z","iopub.execute_input":"2024-04-01T17:52:24.995884Z","iopub.status.idle":"2024-04-01T17:52:25.298579Z","shell.execute_reply.started":"2024-04-01T17:52:24.995857Z","shell.execute_reply":"2024-04-01T17:52:25.297608Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0c76fc8b1bb94f14ad3b53eb2992cb0b"}},"metadata":{}}]},{"cell_type":"markdown","source":"# Preprocessing:","metadata":{}},{"cell_type":"code","source":"def tokenize_and_align_labels(examples):\n    tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n\n    labels = []\n    for i, label in enumerate(examples[f\"ner_tags\"]):\n        word_ids = tokenized_inputs.word_ids(batch_index=i)\n        previous_word_idx = None\n        label_ids = []\n        for word_idx in word_ids:\n            if word_idx is None:\n                label_ids.append(-100)\n            elif word_idx != previous_word_idx:\n                label_ids.append(label[word_idx])\n            else:\n                label_ids.append(-100)\n            previous_word_idx = word_idx\n        labels.append(label_ids)\n\n    tokenized_inputs[\"labels\"] = labels\n    return tokenized_inputs","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:52:25.301730Z","iopub.execute_input":"2024-04-01T17:52:25.302427Z","iopub.status.idle":"2024-04-01T17:52:25.311414Z","shell.execute_reply.started":"2024-04-01T17:52:25.302388Z","shell.execute_reply":"2024-04-01T17:52:25.310413Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"microsoft/deberta-v3-large\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:52:25.312845Z","iopub.execute_input":"2024-04-01T17:52:25.313276Z","iopub.status.idle":"2024-04-01T17:52:27.248890Z","shell.execute_reply.started":"2024-04-01T17:52:25.313239Z","shell.execute_reply":"2024-04-01T17:52:27.248035Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenized_datasets = raw_datasets.map(tokenize_and_align_labels,\n                                      batched=True,\n                                      remove_columns=raw_datasets[\"train\"].column_names)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:52:27.249923Z","iopub.execute_input":"2024-04-01T17:52:27.250176Z","iopub.status.idle":"2024-04-01T17:52:30.425970Z","shell.execute_reply.started":"2024-04-01T17:52:27.250154Z","shell.execute_reply":"2024-04-01T17:52:30.425052Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/15 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f69b7c9b1d8347cc9550f03f361baace"}},"metadata":{}},{"name":"stderr","text":"Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6acfca6136dd48f589cda9e83c9a5486"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/4 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8844bead617d458aad5a2e3468afcb97"}},"metadata":{}}]},{"cell_type":"markdown","source":"# DataLoaders with DataCollator:","metadata":{}},{"cell_type":"code","source":"data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n\ntrain_dataloader = DataLoader(tokenized_datasets[\"train\"],\n                              shuffle=True,\n                              collate_fn=data_collator,\n                              batch_size=8)\n\neval_dataloader = DataLoader(tokenized_datasets[\"validation\"],\n                             collate_fn=data_collator,\n                             batch_size=8)\n\ntest_dataloader = DataLoader(tokenized_datasets[\"test\"],\n                             collate_fn=data_collator,\n                             batch_size=8)","metadata":{"id":"lzoOszGt-5aK","execution":{"iopub.status.busy":"2024-04-01T17:52:30.427477Z","iopub.execute_input":"2024-04-01T17:52:30.428138Z","iopub.status.idle":"2024-04-01T17:52:30.434402Z","shell.execute_reply.started":"2024-04-01T17:52:30.428101Z","shell.execute_reply":"2024-04-01T17:52:30.433423Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# Initialize model:","metadata":{"id":"k2aj1X-5ZE-6"}},{"cell_type":"code","source":"ner_feature = raw_datasets[\"train\"].features[\"ner_tags\"]\nlabel_names = ner_feature.feature.names\nlabel_names\n\nid2label = {i: label for i, label in enumerate(label_names)}\nlabel2id = {v: k for k, v in id2label.items()}\n\nmodel = AutoModelForTokenClassification.from_pretrained(model_checkpoint, id2label=id2label, label2id=label2id)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wHGIQKuX_KsB","outputId":"1cb7afa5-c25b-4ecc-e038-5d66808a4c52","execution":{"iopub.status.busy":"2024-04-01T17:52:30.435401Z","iopub.execute_input":"2024-04-01T17:52:30.435669Z","iopub.status.idle":"2024-04-01T17:52:31.538914Z","shell.execute_reply.started":"2024-04-01T17:52:30.435646Z","shell.execute_reply":"2024-04-01T17:52:31.538155Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of DebertaV2ForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Optimizer and Learning Rate Scheduler:","metadata":{"id":"tHxtDO_dZ3nF"}},{"cell_type":"code","source":"optimizer = Adam(model.parameters(), lr=2e-5, betas=(0.9, 0.999), eps=1e-08)","metadata":{"id":"B9gxZ1HF_0He","execution":{"iopub.status.busy":"2024-04-01T17:52:31.540166Z","iopub.execute_input":"2024-04-01T17:52:31.540526Z","iopub.status.idle":"2024-04-01T17:52:31.547510Z","shell.execute_reply.started":"2024-04-01T17:52:31.540499Z","shell.execute_reply":"2024-04-01T17:52:31.546600Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"num_train_epochs = 3\nnum_update_steps_per_epoch = len(train_dataloader)\nnum_training_steps = num_train_epochs * num_update_steps_per_epoch\n\nlr_scheduler = get_scheduler(\"linear\",\n                             optimizer=optimizer,\n                             num_warmup_steps=0,\n                             num_training_steps=num_training_steps)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:52:31.550143Z","iopub.execute_input":"2024-04-01T17:52:31.550437Z","iopub.status.idle":"2024-04-01T17:52:31.558127Z","shell.execute_reply.started":"2024-04-01T17:52:31.550407Z","shell.execute_reply":"2024-04-01T17:52:31.557396Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"markdown","source":"# Accelerator:","metadata":{"id":"jQ4KnZrwZ5tW"}},{"cell_type":"code","source":"accelerator = Accelerator()\nmodel, optimizer, train_dataloader, eval_dataloader, test_dataloader = accelerator.prepare(model, optimizer, train_dataloader, eval_dataloader, test_dataloader)","metadata":{"id":"OY6GwcEl_5TY","execution":{"iopub.status.busy":"2024-04-01T17:52:31.559137Z","iopub.execute_input":"2024-04-01T17:52:31.559505Z","iopub.status.idle":"2024-04-01T17:52:32.253052Z","shell.execute_reply.started":"2024-04-01T17:52:31.559481Z","shell.execute_reply":"2024-04-01T17:52:32.252168Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# Postprocessing:","metadata":{"id":"v1pAG5YHaOAh"}},{"cell_type":"code","source":"def postprocess(predictions, labels):\n    predictions = predictions.detach().cpu().clone().numpy()\n    labels = labels.detach().cpu().clone().numpy()\n    \n    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n    true_predictions = [\n        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n        for prediction, label in zip(predictions, labels)\n    ]\n    return true_labels, true_predictions","metadata":{"id":"xU5os9J2B0Am","execution":{"iopub.status.busy":"2024-04-01T17:52:32.254139Z","iopub.execute_input":"2024-04-01T17:52:32.254441Z","iopub.status.idle":"2024-04-01T17:52:32.261223Z","shell.execute_reply.started":"2024-04-01T17:52:32.254415Z","shell.execute_reply":"2024-04-01T17:52:32.260205Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"# Finetuning:","metadata":{"id":"yX2iXFe7aV_e"}},{"cell_type":"markdown","source":"## Evaluation metric:","metadata":{}},{"cell_type":"code","source":"metric = evaluate.load(\"seqeval\")","metadata":{"id":"ghrT1EBRDDuo","execution":{"iopub.status.busy":"2024-04-01T17:52:32.262429Z","iopub.execute_input":"2024-04-01T17:52:32.262729Z","iopub.status.idle":"2024-04-01T17:52:32.633009Z","shell.execute_reply.started":"2024-04-01T17:52:32.262696Z","shell.execute_reply":"2024-04-01T17:52:32.632047Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"## Training and validation:","metadata":{"id":"qCqVPbUEZphp"}},{"cell_type":"code","source":"training_losses = []\nvalidation_losses = []\n\nprogress_bar = tqdm(range(num_train_epochs * len(train_dataloader)))\n\nfor epoch in range(num_train_epochs):\n    model.train()\n    total_train_loss = 0\n    for batch in train_dataloader:\n        outputs = model(**batch)\n        loss = outputs.loss\n        total_train_loss += loss.item()\n        \n        accelerator.backward(loss)\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n\n    average_train_loss = total_train_loss / len(train_dataloader)\n    training_losses.append(average_train_loss)\n    \n    model.eval()\n    total_eval_loss = 0\n    for batch in eval_dataloader:\n        with torch.no_grad():\n            outputs = model(**batch)\n            loss = outputs.loss\n            total_eval_loss += loss.item()\n\n        predictions = outputs.logits.argmax(dim=-1)\n        labels = batch[\"labels\"]\n        \n        predictions = accelerator.pad_across_processes(predictions, dim=1, pad_index=-100)\n        labels = accelerator.pad_across_processes(labels, dim=1, pad_index=-100)\n        \n        predictions_gathered = accelerator.gather(predictions)\n        labels_gathered = accelerator.gather(labels)\n        \n        true_predictions, true_labels = postprocess(predictions_gathered, labels_gathered)\n        metric.add_batch(predictions=true_predictions, references=true_labels)\n\n    average_eval_loss = total_eval_loss / len(eval_dataloader)\n    validation_losses.append(average_eval_loss)\n    \n    results = metric.compute()\n    overalls = {key: results[f\"overall_{key}\"] for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]}\n    \n    print(f\"Epoch {epoch+1}, Training Loss: {average_train_loss:.4f}, Validation Loss: {average_eval_loss:.4f}, \"\n          f\"Precision: {overalls['precision']:.4f}, Recall: {overalls['recall']:.4f}, \"\n          f\"F1: {overalls['f1']:.4f}, Accuracy: {overalls['accuracy']:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-01T17:52:32.634327Z","iopub.execute_input":"2024-04-01T17:52:32.634626Z","iopub.status.idle":"2024-04-01T18:31:47.366737Z","shell.execute_reply.started":"2024-04-01T17:52:32.634601Z","shell.execute_reply":"2024-04-01T18:31:47.365783Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/5268 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e4de1fe867ec4c14909702142ea4191e"}},"metadata":{}},{"name":"stdout","text":"Epoch 1, Training Loss: 0.0694, Validation Loss: 0.0337, Precision: 0.9576, Recall: 0.9502, F1: 0.9539, Accuracy: 0.9921\nEpoch 2, Training Loss: 0.0203, Validation Loss: 0.0288, Precision: 0.9685, Recall: 0.9601, F1: 0.9643, Accuracy: 0.9938\nEpoch 3, Training Loss: 0.0099, Validation Loss: 0.0300, Precision: 0.9705, Recall: 0.9628, F1: 0.9666, Accuracy: 0.9939\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Evaluation on Test Dataset:","metadata":{}},{"cell_type":"code","source":"model.eval()\n\ntest_losses = []\ntotal_test_loss = 0\n\nwith torch.no_grad():\n    for batch in test_dataloader:\n        outputs = model(**batch)\n        \n        loss = outputs.loss\n        total_test_loss += loss.item()\n        \n        predictions = outputs.logits.argmax(dim=-1)\n        labels = batch[\"labels\"]\n        \n        predictions, labels = accelerator.gather((predictions, labels))\n        \n        true_predictions, true_labels = postprocess(predictions, labels)\n        metric.add_batch(predictions=true_predictions, references=true_labels)\n\naverage_test_loss = total_test_loss / len(test_dataloader)\ntest_losses.append(average_test_loss)\n\nresults = metric.compute()\noveralls = {key: results[f\"overall_{key}\"] for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]}\n\n# Affichage des résultats\nprint(f\"Test Loss: {average_test_loss:.4f}, \"\n      f\"Precision: {overalls['precision']:.4f}, \"\n      f\"Recall: {overalls['recall']:.4f}, \"\n      f\"F1: {overalls['f1']:.4f}, \"\n      f\"Accuracy: {overalls['accuracy']:.4f}\")","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:31:47.368317Z","iopub.execute_input":"2024-04-01T18:31:47.368621Z","iopub.status.idle":"2024-04-01T18:32:31.460519Z","shell.execute_reply.started":"2024-04-01T18:31:47.368595Z","shell.execute_reply":"2024-04-01T18:32:31.459525Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Test Loss: 0.1064, Precision: 0.9347, Recall: 0.9224, F1: 0.9285, Accuracy: 0.9856\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Inference:","metadata":{}},{"cell_type":"code","source":"token_classifier = pipeline(\"token-classification\",\n                            model=model,\n                            tokenizer=tokenizer,\n                            aggregation_strategy=\"simple\")\n\ntext = \"My name is Jack and I work with Clara at Meta in Paris.\"\n\nresults = token_classifier(text)\n\nfor result in results:\n    print(result)","metadata":{"execution":{"iopub.status.busy":"2024-04-01T18:32:31.461818Z","iopub.execute_input":"2024-04-01T18:32:31.462153Z","iopub.status.idle":"2024-04-01T18:32:33.557804Z","shell.execute_reply.started":"2024-04-01T18:32:31.462125Z","shell.execute_reply":"2024-04-01T18:32:33.556830Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"{'entity_group': 'PER', 'score': 0.9965789, 'word': 'Jack', 'start': 10, 'end': 15}\n{'entity_group': 'PER', 'score': 0.99711335, 'word': 'Clara', 'start': 31, 'end': 37}\n{'entity_group': 'ORG', 'score': 0.9002738, 'word': 'Meta', 'start': 40, 'end': 45}\n{'entity_group': 'LOC', 'score': 0.9983719, 'word': 'Paris', 'start': 48, 'end': 54}\n","output_type":"stream"}]}]}